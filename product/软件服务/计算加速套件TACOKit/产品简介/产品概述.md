## 简介
计算加速套件TACO Kit（TencentCloud Accelerated Computing Optimization Kit）是一种异构计算加速软件服务，具备领先的 GPU 共享技术和业界唯一的 GPU 在离线混部能力，搭配腾讯自研的软硬件协同优化组件和硬件厂商特有优化方案，支持物理机、云服务器、容器等产品的计算加速、图形渲染、视频转码各个应用场景，帮助用户实现全方位全场景的降本增效。


其中，AI 加速引擎 TACO Train 和 TACO Infer 是腾讯云虚拟化团队依托云帆团队，立足于腾讯内部丰富的 AI 业务场景，深耕训练框架优化、分布式框架优化、网络通信优化、推理性能优化等关键技术，携手打造的一整套 AI 加速方案。为了更好的服务用户，腾讯云决定将内部深度优化的加速方案免费提供给公有云用户，助力广大用户提高 AI 产品迭代效率。其架构示意图如下所示：
![](https://qcloudimg.tencent-cloud.cn/raw/7b0e30f4cd9d4046d8b5f9676a50979d.png)


## TACO Train AI 训练加速引擎

### 背景信息
随着 AI 模型规模的扩大及训练数据的增多，用户对模型的迭代效率要求也随之增长，单个 GPU 的算力已无法满足大部分业务场景，使用单机多卡或多机多卡训练已成为趋势。
目前，单机多卡训练场景的参数借助 NVIDIA NVLINK 技术，已获取较好的解决方案。对于多机多卡场景，网卡厂商针对其对网络通信的强依赖，提供了高速互联技术 Infiniband 或 RoCE，虽使多机通信效率大幅提升，但成本也大幅增加。如何在25G或50G VPC 普通网络环境下提升分布式训练系统的通信效率，已成为公有云厂商需解决的问题。

### TACO Train 简介
目前业内已具备较多分布式训练的加速技术，例如多级通信、多流通信、梯度融合、压缩通信等。TACO Train 也引入了类似的加速技术。同时，TACO Train 具备不同于业界其他方案的创新点，自定义用户态协议栈 HARP，有效地解决了 VPC 环境下多机多卡训练中的网络通信问题。

TACO Train 是腾讯云**异构计算团队**基于 IaaS 资源推出的 AI 训练加速引擎，为用户提供开箱即用的 AI 训练套件。TACO Train 背靠**云帆Oteam**，基于腾讯内部丰富的 AI 业务场景，提供自底向上的网络通信、分布式策略及训练框架等多层级的优化，是一套全生态的训练加速方案。

### 训练加速组件
TACO Train 目前提供了三个训练加速组件：
- **Tencent Tensorflow 1.15**：基于 Tensorflow 1.15深度优化的训练框架（以下简称 TTF）。
- **LightCC**：基于 Horovod 深度优化的分布式训练框架。
- **HARP**：自研用户态网络协议栈。                         

详细介绍如下：

<dx-accordion>
::: TTF
TensorFlow 是深度学习领域中应用最广泛的开源框架之一，但是在很多业务场景下，开源 Tensorflow 有其特定的限制。为了解决实际业务中遇到的问题，TencentTensorflow（以下简称 TTF）提供了以下能力：

- 相比原始的静态 Embedding，高维稀疏动态 Embedding 帮助用户在不需要重新训练的条件下，动态添加和删除特征，按需使用内存，避免 Hash 冲突，同时保留原始 TF 的 API 设计风格。
- 混合精度在原有实现的基础上增加了调整精度的策略，根据 loss 的状态自动在全精度和半精度之间切换，避免精度损失。
- 针对特定业务场景的 XLA，Grappler 图优化，以及自适应编译框架解决冗余编译的问题。
- 开源 TF 1版本不再提供对 Ampere GPU 的支持，但考虑到较多用户仍在使用 TF 1.15版本的问题，TTF 添加了对 CUDA 11的支持，让用户可以使用 A100来进行模型训练。

:::
::: LightCC

LightCC 是基于 Horovod 深度优化的分布式训练框架，在保留了原生 Horovod 的易用性上，增加了性能更好的通信方式。相比 Horovod，LightCC 提供了以下能力：
- 2D AllReduce 充分利用通信带宽。
- 高效的梯度融合方式。
- TOPK 压缩通信，降低通信量，提高传输效率。


LightCC API 与 Horovod 完全兼容，业务不需要任何改动，无缝迁移。


:::
::: HARP
随着网络硬件技术的发展，网卡的速度从10G增长到100G甚至更高，在数据中心大量部署使用。但目前普遍使用的内核网络协议栈存在着一些必要的开销，使其不能很好地利用高速网络设备。为解决该问题，腾讯云自研了用户态网络协议栈 HARP，可以以 Plug-in 的方式集成到 NCCL 中，无需任何业务改动，加速云上分布式训练性能。在 VPC 的环境下，相比传统的内核协议栈，HARP 提供了以下的能力：

- 支持全链路内存零拷贝，HARP 协议栈提供特定的 buffer 给应用，使应用的数据经过HARP协议栈处理后由网卡直接进行收发，消除内核协议栈中耗时及占用 CPU 较高的多次内存拷贝操作。
- 支持协议栈多实例隔离，即应用可以在多个 CPU core 上创建特定协议栈实例处理网络报文，每个实例间相互隔离，保证性能线性增长。
- 数据平面无锁设计，HARP 协议栈内部保证网络 session 的数据仅在创建该 session 的 CPU core 上，使用特定的协议栈实例处理。减少了内核中同步锁的开销，也降低了 CPU 的 Cache Miss 率，大幅提升网络数据的处理性能。



内核协议栈与用户态协议栈 HARP 对比图如下：
![](https://qcloudimg.tencent-cloud.cn/raw/e94f6692167290785fbbbf900c725918.png)  

:::
</dx-accordion>



## TACO Infer AI 推理加速引擎

### 背景信息

长期以来，AI 算法用于生产环境大规模模型的推理部署，一直存在多维度的需考虑因素：
- 从企业的角度，需考虑如何选择硬件/基础设施来部署业务从而获得最佳投入产出比。例如，如何选择一款加速芯片，满足稳定运行业务模型、业务运行过程中硬件利用率、业务部署是否足够灵活、部署方案的可迁移性等。
- 从系统、测试和运维工程师的角度，面对开发社区算法的快速迭代，需考虑如何以不同框架训练的模型高效且稳定地部署来自上游业务算法，如何整合、利用社区及硬件厂商提供的加速库及软件，对接不同模型、不同硬件，如何将加速软件和自身业务的定制化需求有机结合。而面对不同业务细分场景，需考虑如何标准化一套接口高效地优化和部署业务模型等。


TACO Infer 在上述背景下，整合腾讯云及硬件厂商研发资源，面向 AI 负载倾力打造的异构加速引擎。帮助用户快速接入不同硬件，实现通用、易用的优化、加速、部署，避免一款硬件/加速芯片、一套方案的窘境，从而全面提高生产力。


### 功能介绍

TACO Infer AI 推理加速引擎是一款计算加速推理套件，帮助您简洁、无侵入业务代码地一站式解决 AI 模型在生产环境中应用的问题。具备以下功能特点：

#### 简洁部署，无侵入业务代码接入
- TACO Infer 仅有一行简洁的优化接口。
- 透明无感接入业务，不改变用户的模型格式，输入的模型格式和输出一致，用户可以保持其一贯的使用和部署习惯。
- 提供插件式的第三方开发接口，支持适配不同业务场景。


#### 软硬件兼容
- 支持多种框架模型，TenSorflow 已开放支持，pytorch，onnx 等框架已在筹备中。
- 兼容 CPU、GPU、NPU 等多种加速硬件。
- 可运行在虚拟机、物理机、容器等各种环境。


#### 集成硬件厂商定向开源的加速方案
-	厂商加速方案集成。
- 编译优化。
- 图优化和算子优化。

